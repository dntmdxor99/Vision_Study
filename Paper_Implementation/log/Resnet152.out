nohup: ignoring input
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [32, 64, 112, 112]           9,408
       BatchNorm2d-2         [32, 64, 112, 112]             128
              ReLU-3         [32, 64, 112, 112]               0
         MaxPool2d-4           [32, 64, 56, 56]               0
            Conv2d-5           [32, 64, 56, 56]           4,096
       BatchNorm2d-6           [32, 64, 56, 56]             128
              ReLU-7           [32, 64, 56, 56]               0
            Conv2d-8           [32, 64, 56, 56]          36,864
       BatchNorm2d-9           [32, 64, 56, 56]             128
             ReLU-10           [32, 64, 56, 56]               0
           Conv2d-11          [32, 256, 56, 56]          16,384
      BatchNorm2d-12          [32, 256, 56, 56]             512
           Conv2d-13          [32, 256, 56, 56]          16,384
      BatchNorm2d-14          [32, 256, 56, 56]             512
             ReLU-15          [32, 256, 56, 56]               0
       BottleNeck-16          [32, 256, 56, 56]               0
           Conv2d-17           [32, 64, 56, 56]          16,384
      BatchNorm2d-18           [32, 64, 56, 56]             128
             ReLU-19           [32, 64, 56, 56]               0
           Conv2d-20           [32, 64, 56, 56]          36,864
      BatchNorm2d-21           [32, 64, 56, 56]             128
             ReLU-22           [32, 64, 56, 56]               0
           Conv2d-23          [32, 256, 56, 56]          16,384
      BatchNorm2d-24          [32, 256, 56, 56]             512
             ReLU-25          [32, 256, 56, 56]               0
       BottleNeck-26          [32, 256, 56, 56]               0
           Conv2d-27           [32, 64, 56, 56]          16,384
      BatchNorm2d-28           [32, 64, 56, 56]             128
             ReLU-29           [32, 64, 56, 56]               0
           Conv2d-30           [32, 64, 56, 56]          36,864
      BatchNorm2d-31           [32, 64, 56, 56]             128
             ReLU-32           [32, 64, 56, 56]               0
           Conv2d-33          [32, 256, 56, 56]          16,384
      BatchNorm2d-34          [32, 256, 56, 56]             512
             ReLU-35          [32, 256, 56, 56]               0
       BottleNeck-36          [32, 256, 56, 56]               0
           Conv2d-37          [32, 128, 56, 56]          32,768
      BatchNorm2d-38          [32, 128, 56, 56]             256
             ReLU-39          [32, 128, 56, 56]               0
           Conv2d-40          [32, 128, 28, 28]         147,456
      BatchNorm2d-41          [32, 128, 28, 28]             256
             ReLU-42          [32, 128, 28, 28]               0
           Conv2d-43          [32, 512, 28, 28]          65,536
      BatchNorm2d-44          [32, 512, 28, 28]           1,024
           Conv2d-45          [32, 512, 28, 28]         131,072
      BatchNorm2d-46          [32, 512, 28, 28]           1,024
             ReLU-47          [32, 512, 28, 28]               0
       BottleNeck-48          [32, 512, 28, 28]               0
           Conv2d-49          [32, 128, 28, 28]          65,536
      BatchNorm2d-50          [32, 128, 28, 28]             256
             ReLU-51          [32, 128, 28, 28]               0
           Conv2d-52          [32, 128, 28, 28]         147,456
      BatchNorm2d-53          [32, 128, 28, 28]             256
             ReLU-54          [32, 128, 28, 28]               0
           Conv2d-55          [32, 512, 28, 28]          65,536
      BatchNorm2d-56          [32, 512, 28, 28]           1,024
             ReLU-57          [32, 512, 28, 28]               0
       BottleNeck-58          [32, 512, 28, 28]               0
           Conv2d-59          [32, 128, 28, 28]          65,536
      BatchNorm2d-60          [32, 128, 28, 28]             256
             ReLU-61          [32, 128, 28, 28]               0
           Conv2d-62          [32, 128, 28, 28]         147,456
      BatchNorm2d-63          [32, 128, 28, 28]             256
             ReLU-64          [32, 128, 28, 28]               0
           Conv2d-65          [32, 512, 28, 28]          65,536
      BatchNorm2d-66          [32, 512, 28, 28]           1,024
             ReLU-67          [32, 512, 28, 28]               0
       BottleNeck-68          [32, 512, 28, 28]               0
           Conv2d-69          [32, 128, 28, 28]          65,536
      BatchNorm2d-70          [32, 128, 28, 28]             256
             ReLU-71          [32, 128, 28, 28]               0
           Conv2d-72          [32, 128, 28, 28]         147,456
      BatchNorm2d-73          [32, 128, 28, 28]             256
             ReLU-74          [32, 128, 28, 28]               0
           Conv2d-75          [32, 512, 28, 28]          65,536
      BatchNorm2d-76          [32, 512, 28, 28]           1,024
             ReLU-77          [32, 512, 28, 28]               0
       BottleNeck-78          [32, 512, 28, 28]               0
           Conv2d-79          [32, 128, 28, 28]          65,536
      BatchNorm2d-80          [32, 128, 28, 28]             256
             ReLU-81          [32, 128, 28, 28]               0
           Conv2d-82          [32, 128, 28, 28]         147,456
      BatchNorm2d-83          [32, 128, 28, 28]             256
             ReLU-84          [32, 128, 28, 28]               0
           Conv2d-85          [32, 512, 28, 28]          65,536
      BatchNorm2d-86          [32, 512, 28, 28]           1,024
             ReLU-87          [32, 512, 28, 28]               0
       BottleNeck-88          [32, 512, 28, 28]               0
           Conv2d-89          [32, 128, 28, 28]          65,536
      BatchNorm2d-90          [32, 128, 28, 28]             256
             ReLU-91          [32, 128, 28, 28]               0
           Conv2d-92          [32, 128, 28, 28]         147,456
      BatchNorm2d-93          [32, 128, 28, 28]             256
             ReLU-94          [32, 128, 28, 28]               0
           Conv2d-95          [32, 512, 28, 28]          65,536
      BatchNorm2d-96          [32, 512, 28, 28]           1,024
             ReLU-97          [32, 512, 28, 28]               0
       BottleNeck-98          [32, 512, 28, 28]               0
           Conv2d-99          [32, 128, 28, 28]          65,536
     BatchNorm2d-100          [32, 128, 28, 28]             256
            ReLU-101          [32, 128, 28, 28]               0
          Conv2d-102          [32, 128, 28, 28]         147,456
     BatchNorm2d-103          [32, 128, 28, 28]             256
            ReLU-104          [32, 128, 28, 28]               0
          Conv2d-105          [32, 512, 28, 28]          65,536
     BatchNorm2d-106          [32, 512, 28, 28]           1,024
            ReLU-107          [32, 512, 28, 28]               0
      BottleNeck-108          [32, 512, 28, 28]               0
          Conv2d-109          [32, 128, 28, 28]          65,536
     BatchNorm2d-110          [32, 128, 28, 28]             256
            ReLU-111          [32, 128, 28, 28]               0
          Conv2d-112          [32, 128, 28, 28]         147,456
     BatchNorm2d-113          [32, 128, 28, 28]             256
            ReLU-114          [32, 128, 28, 28]               0
          Conv2d-115          [32, 512, 28, 28]          65,536
     BatchNorm2d-116          [32, 512, 28, 28]           1,024
            ReLU-117          [32, 512, 28, 28]               0
      BottleNeck-118          [32, 512, 28, 28]               0
          Conv2d-119          [32, 256, 28, 28]         131,072
     BatchNorm2d-120          [32, 256, 28, 28]             512
            ReLU-121          [32, 256, 28, 28]               0
          Conv2d-122          [32, 256, 14, 14]         589,824
     BatchNorm2d-123          [32, 256, 14, 14]             512
            ReLU-124          [32, 256, 14, 14]               0
          Conv2d-125         [32, 1024, 14, 14]         262,144
     BatchNorm2d-126         [32, 1024, 14, 14]           2,048
          Conv2d-127         [32, 1024, 14, 14]         524,288
     BatchNorm2d-128         [32, 1024, 14, 14]           2,048
            ReLU-129         [32, 1024, 14, 14]               0
      BottleNeck-130         [32, 1024, 14, 14]               0
          Conv2d-131          [32, 256, 14, 14]         262,144
     BatchNorm2d-132          [32, 256, 14, 14]             512
            ReLU-133          [32, 256, 14, 14]               0
          Conv2d-134          [32, 256, 14, 14]         589,824
     BatchNorm2d-135          [32, 256, 14, 14]             512
            ReLU-136          [32, 256, 14, 14]               0
          Conv2d-137         [32, 1024, 14, 14]         262,144
     BatchNorm2d-138         [32, 1024, 14, 14]           2,048
            ReLU-139         [32, 1024, 14, 14]               0
      BottleNeck-140         [32, 1024, 14, 14]               0
          Conv2d-141          [32, 256, 14, 14]         262,144
     BatchNorm2d-142          [32, 256, 14, 14]             512
            ReLU-143          [32, 256, 14, 14]               0
          Conv2d-144          [32, 256, 14, 14]         589,824
     BatchNorm2d-145          [32, 256, 14, 14]             512
            ReLU-146          [32, 256, 14, 14]               0
          Conv2d-147         [32, 1024, 14, 14]         262,144
     BatchNorm2d-148         [32, 1024, 14, 14]           2,048
            ReLU-149         [32, 1024, 14, 14]               0
      BottleNeck-150         [32, 1024, 14, 14]               0
          Conv2d-151          [32, 256, 14, 14]         262,144
     BatchNorm2d-152          [32, 256, 14, 14]             512
            ReLU-153          [32, 256, 14, 14]               0
          Conv2d-154          [32, 256, 14, 14]         589,824
     BatchNorm2d-155          [32, 256, 14, 14]             512
            ReLU-156          [32, 256, 14, 14]               0
          Conv2d-157         [32, 1024, 14, 14]         262,144
     BatchNorm2d-158         [32, 1024, 14, 14]           2,048
            ReLU-159         [32, 1024, 14, 14]               0
      BottleNeck-160         [32, 1024, 14, 14]               0
          Conv2d-161          [32, 256, 14, 14]         262,144
     BatchNorm2d-162          [32, 256, 14, 14]             512
            ReLU-163          [32, 256, 14, 14]               0
          Conv2d-164          [32, 256, 14, 14]         589,824
     BatchNorm2d-165          [32, 256, 14, 14]             512
            ReLU-166          [32, 256, 14, 14]               0
          Conv2d-167         [32, 1024, 14, 14]         262,144
     BatchNorm2d-168         [32, 1024, 14, 14]           2,048
            ReLU-169         [32, 1024, 14, 14]               0
      BottleNeck-170         [32, 1024, 14, 14]               0
          Conv2d-171          [32, 256, 14, 14]         262,144
     BatchNorm2d-172          [32, 256, 14, 14]             512
            ReLU-173          [32, 256, 14, 14]               0
          Conv2d-174          [32, 256, 14, 14]         589,824
     BatchNorm2d-175          [32, 256, 14, 14]             512
            ReLU-176          [32, 256, 14, 14]               0
          Conv2d-177         [32, 1024, 14, 14]         262,144
     BatchNorm2d-178         [32, 1024, 14, 14]           2,048
            ReLU-179         [32, 1024, 14, 14]               0
      BottleNeck-180         [32, 1024, 14, 14]               0
          Conv2d-181          [32, 256, 14, 14]         262,144
     BatchNorm2d-182          [32, 256, 14, 14]             512
            ReLU-183          [32, 256, 14, 14]               0
          Conv2d-184          [32, 256, 14, 14]         589,824
     BatchNorm2d-185          [32, 256, 14, 14]             512
            ReLU-186          [32, 256, 14, 14]               0
          Conv2d-187         [32, 1024, 14, 14]         262,144
     BatchNorm2d-188         [32, 1024, 14, 14]           2,048
            ReLU-189         [32, 1024, 14, 14]               0
      BottleNeck-190         [32, 1024, 14, 14]               0
          Conv2d-191          [32, 256, 14, 14]         262,144
     BatchNorm2d-192          [32, 256, 14, 14]             512
            ReLU-193          [32, 256, 14, 14]               0
          Conv2d-194          [32, 256, 14, 14]         589,824
     BatchNorm2d-195          [32, 256, 14, 14]             512
            ReLU-196          [32, 256, 14, 14]               0
          Conv2d-197         [32, 1024, 14, 14]         262,144
     BatchNorm2d-198         [32, 1024, 14, 14]           2,048
            ReLU-199         [32, 1024, 14, 14]               0
      BottleNeck-200         [32, 1024, 14, 14]               0
          Conv2d-201          [32, 256, 14, 14]         262,144
     BatchNorm2d-202          [32, 256, 14, 14]             512
            ReLU-203          [32, 256, 14, 14]               0
          Conv2d-204          [32, 256, 14, 14]         589,824
     BatchNorm2d-205          [32, 256, 14, 14]             512
            ReLU-206          [32, 256, 14, 14]               0
          Conv2d-207         [32, 1024, 14, 14]         262,144
     BatchNorm2d-208         [32, 1024, 14, 14]           2,048
            ReLU-209         [32, 1024, 14, 14]               0
      BottleNeck-210         [32, 1024, 14, 14]               0
          Conv2d-211          [32, 256, 14, 14]         262,144
     BatchNorm2d-212          [32, 256, 14, 14]             512
            ReLU-213          [32, 256, 14, 14]               0
          Conv2d-214          [32, 256, 14, 14]         589,824
     BatchNorm2d-215          [32, 256, 14, 14]             512
            ReLU-216          [32, 256, 14, 14]               0
          Conv2d-217         [32, 1024, 14, 14]         262,144
     BatchNorm2d-218         [32, 1024, 14, 14]           2,048
            ReLU-219         [32, 1024, 14, 14]               0
      BottleNeck-220         [32, 1024, 14, 14]               0
          Conv2d-221          [32, 256, 14, 14]         262,144
     BatchNorm2d-222          [32, 256, 14, 14]             512
            ReLU-223          [32, 256, 14, 14]               0
          Conv2d-224          [32, 256, 14, 14]         589,824
     BatchNorm2d-225          [32, 256, 14, 14]             512
            ReLU-226          [32, 256, 14, 14]               0
          Conv2d-227         [32, 1024, 14, 14]         262,144
     BatchNorm2d-228         [32, 1024, 14, 14]           2,048
            ReLU-229         [32, 1024, 14, 14]               0
      BottleNeck-230         [32, 1024, 14, 14]               0
          Conv2d-231          [32, 256, 14, 14]         262,144
     BatchNorm2d-232          [32, 256, 14, 14]             512
            ReLU-233          [32, 256, 14, 14]               0
          Conv2d-234          [32, 256, 14, 14]         589,824
     BatchNorm2d-235          [32, 256, 14, 14]             512
            ReLU-236          [32, 256, 14, 14]               0
          Conv2d-237         [32, 1024, 14, 14]         262,144
     BatchNorm2d-238         [32, 1024, 14, 14]           2,048
            ReLU-239         [32, 1024, 14, 14]               0
      BottleNeck-240         [32, 1024, 14, 14]               0
          Conv2d-241          [32, 256, 14, 14]         262,144
     BatchNorm2d-242          [32, 256, 14, 14]             512
            ReLU-243          [32, 256, 14, 14]               0
          Conv2d-244          [32, 256, 14, 14]         589,824
     BatchNorm2d-245          [32, 256, 14, 14]             512
            ReLU-246          [32, 256, 14, 14]               0
          Conv2d-247         [32, 1024, 14, 14]         262,144
     BatchNorm2d-248         [32, 1024, 14, 14]           2,048
            ReLU-249         [32, 1024, 14, 14]               0
      BottleNeck-250         [32, 1024, 14, 14]               0
          Conv2d-251          [32, 256, 14, 14]         262,144
     BatchNorm2d-252          [32, 256, 14, 14]             512
            ReLU-253          [32, 256, 14, 14]               0
          Conv2d-254          [32, 256, 14, 14]         589,824
     BatchNorm2d-255          [32, 256, 14, 14]             512
            ReLU-256          [32, 256, 14, 14]               0
          Conv2d-257         [32, 1024, 14, 14]         262,144
     BatchNorm2d-258         [32, 1024, 14, 14]           2,048
            ReLU-259         [32, 1024, 14, 14]               0
      BottleNeck-260         [32, 1024, 14, 14]               0
          Conv2d-261          [32, 256, 14, 14]         262,144
     BatchNorm2d-262          [32, 256, 14, 14]             512
            ReLU-263          [32, 256, 14, 14]               0
          Conv2d-264          [32, 256, 14, 14]         589,824
     BatchNorm2d-265          [32, 256, 14, 14]             512
            ReLU-266          [32, 256, 14, 14]               0
          Conv2d-267         [32, 1024, 14, 14]         262,144
     BatchNorm2d-268         [32, 1024, 14, 14]           2,048
            ReLU-269         [32, 1024, 14, 14]               0
      BottleNeck-270         [32, 1024, 14, 14]               0
          Conv2d-271          [32, 256, 14, 14]         262,144
     BatchNorm2d-272          [32, 256, 14, 14]             512
            ReLU-273          [32, 256, 14, 14]               0
          Conv2d-274          [32, 256, 14, 14]         589,824
     BatchNorm2d-275          [32, 256, 14, 14]             512
            ReLU-276          [32, 256, 14, 14]               0
          Conv2d-277         [32, 1024, 14, 14]         262,144
     BatchNorm2d-278         [32, 1024, 14, 14]           2,048
            ReLU-279         [32, 1024, 14, 14]               0
      BottleNeck-280         [32, 1024, 14, 14]               0
          Conv2d-281          [32, 256, 14, 14]         262,144
     BatchNorm2d-282          [32, 256, 14, 14]             512
            ReLU-283          [32, 256, 14, 14]               0
          Conv2d-284          [32, 256, 14, 14]         589,824
     BatchNorm2d-285          [32, 256, 14, 14]             512
            ReLU-286          [32, 256, 14, 14]               0
          Conv2d-287         [32, 1024, 14, 14]         262,144
     BatchNorm2d-288         [32, 1024, 14, 14]           2,048
            ReLU-289         [32, 1024, 14, 14]               0
      BottleNeck-290         [32, 1024, 14, 14]               0
          Conv2d-291          [32, 256, 14, 14]         262,144
     BatchNorm2d-292          [32, 256, 14, 14]             512
            ReLU-293          [32, 256, 14, 14]               0
          Conv2d-294          [32, 256, 14, 14]         589,824
     BatchNorm2d-295          [32, 256, 14, 14]             512
            ReLU-296          [32, 256, 14, 14]               0
          Conv2d-297         [32, 1024, 14, 14]         262,144
     BatchNorm2d-298         [32, 1024, 14, 14]           2,048
            ReLU-299         [32, 1024, 14, 14]               0
      BottleNeck-300         [32, 1024, 14, 14]               0
          Conv2d-301          [32, 256, 14, 14]         262,144
     BatchNorm2d-302          [32, 256, 14, 14]             512
            ReLU-303          [32, 256, 14, 14]               0
          Conv2d-304          [32, 256, 14, 14]         589,824
     BatchNorm2d-305          [32, 256, 14, 14]             512
            ReLU-306          [32, 256, 14, 14]               0
          Conv2d-307         [32, 1024, 14, 14]         262,144
     BatchNorm2d-308         [32, 1024, 14, 14]           2,048
            ReLU-309         [32, 1024, 14, 14]               0
      BottleNeck-310         [32, 1024, 14, 14]               0
          Conv2d-311          [32, 256, 14, 14]         262,144
     BatchNorm2d-312          [32, 256, 14, 14]             512
            ReLU-313          [32, 256, 14, 14]               0
          Conv2d-314          [32, 256, 14, 14]         589,824
     BatchNorm2d-315          [32, 256, 14, 14]             512
            ReLU-316          [32, 256, 14, 14]               0
          Conv2d-317         [32, 1024, 14, 14]         262,144
     BatchNorm2d-318         [32, 1024, 14, 14]           2,048
            ReLU-319         [32, 1024, 14, 14]               0
      BottleNeck-320         [32, 1024, 14, 14]               0
          Conv2d-321          [32, 256, 14, 14]         262,144
     BatchNorm2d-322          [32, 256, 14, 14]             512
            ReLU-323          [32, 256, 14, 14]               0
          Conv2d-324          [32, 256, 14, 14]         589,824
     BatchNorm2d-325          [32, 256, 14, 14]             512
            ReLU-326          [32, 256, 14, 14]               0
          Conv2d-327         [32, 1024, 14, 14]         262,144
     BatchNorm2d-328         [32, 1024, 14, 14]           2,048
            ReLU-329         [32, 1024, 14, 14]               0
      BottleNeck-330         [32, 1024, 14, 14]               0
          Conv2d-331          [32, 256, 14, 14]         262,144
     BatchNorm2d-332          [32, 256, 14, 14]             512
            ReLU-333          [32, 256, 14, 14]               0
          Conv2d-334          [32, 256, 14, 14]         589,824
     BatchNorm2d-335          [32, 256, 14, 14]             512
            ReLU-336          [32, 256, 14, 14]               0
          Conv2d-337         [32, 1024, 14, 14]         262,144
     BatchNorm2d-338         [32, 1024, 14, 14]           2,048
            ReLU-339         [32, 1024, 14, 14]               0
      BottleNeck-340         [32, 1024, 14, 14]               0
          Conv2d-341          [32, 256, 14, 14]         262,144
     BatchNorm2d-342          [32, 256, 14, 14]             512
            ReLU-343          [32, 256, 14, 14]               0
          Conv2d-344          [32, 256, 14, 14]         589,824
     BatchNorm2d-345          [32, 256, 14, 14]             512
            ReLU-346          [32, 256, 14, 14]               0
          Conv2d-347         [32, 1024, 14, 14]         262,144
     BatchNorm2d-348         [32, 1024, 14, 14]           2,048
            ReLU-349         [32, 1024, 14, 14]               0
      BottleNeck-350         [32, 1024, 14, 14]               0
          Conv2d-351          [32, 256, 14, 14]         262,144
     BatchNorm2d-352          [32, 256, 14, 14]             512
            ReLU-353          [32, 256, 14, 14]               0
          Conv2d-354          [32, 256, 14, 14]         589,824
     BatchNorm2d-355          [32, 256, 14, 14]             512
            ReLU-356          [32, 256, 14, 14]               0
          Conv2d-357         [32, 1024, 14, 14]         262,144
     BatchNorm2d-358         [32, 1024, 14, 14]           2,048
            ReLU-359         [32, 1024, 14, 14]               0
      BottleNeck-360         [32, 1024, 14, 14]               0
          Conv2d-361          [32, 256, 14, 14]         262,144
     BatchNorm2d-362          [32, 256, 14, 14]             512
            ReLU-363          [32, 256, 14, 14]               0
          Conv2d-364          [32, 256, 14, 14]         589,824
     BatchNorm2d-365          [32, 256, 14, 14]             512
            ReLU-366          [32, 256, 14, 14]               0
          Conv2d-367         [32, 1024, 14, 14]         262,144
     BatchNorm2d-368         [32, 1024, 14, 14]           2,048
            ReLU-369         [32, 1024, 14, 14]               0
      BottleNeck-370         [32, 1024, 14, 14]               0
          Conv2d-371          [32, 256, 14, 14]         262,144
     BatchNorm2d-372          [32, 256, 14, 14]             512
            ReLU-373          [32, 256, 14, 14]               0
          Conv2d-374          [32, 256, 14, 14]         589,824
     BatchNorm2d-375          [32, 256, 14, 14]             512
            ReLU-376          [32, 256, 14, 14]               0
          Conv2d-377         [32, 1024, 14, 14]         262,144
     BatchNorm2d-378         [32, 1024, 14, 14]           2,048
            ReLU-379         [32, 1024, 14, 14]               0
      BottleNeck-380         [32, 1024, 14, 14]               0
          Conv2d-381          [32, 256, 14, 14]         262,144
     BatchNorm2d-382          [32, 256, 14, 14]             512
            ReLU-383          [32, 256, 14, 14]               0
          Conv2d-384          [32, 256, 14, 14]         589,824
     BatchNorm2d-385          [32, 256, 14, 14]             512
            ReLU-386          [32, 256, 14, 14]               0
          Conv2d-387         [32, 1024, 14, 14]         262,144
     BatchNorm2d-388         [32, 1024, 14, 14]           2,048
            ReLU-389         [32, 1024, 14, 14]               0
      BottleNeck-390         [32, 1024, 14, 14]               0
          Conv2d-391          [32, 256, 14, 14]         262,144
     BatchNorm2d-392          [32, 256, 14, 14]             512
            ReLU-393          [32, 256, 14, 14]               0
          Conv2d-394          [32, 256, 14, 14]         589,824
     BatchNorm2d-395          [32, 256, 14, 14]             512
            ReLU-396          [32, 256, 14, 14]               0
          Conv2d-397         [32, 1024, 14, 14]         262,144
     BatchNorm2d-398         [32, 1024, 14, 14]           2,048
            ReLU-399         [32, 1024, 14, 14]               0
      BottleNeck-400         [32, 1024, 14, 14]               0
          Conv2d-401          [32, 256, 14, 14]         262,144
     BatchNorm2d-402          [32, 256, 14, 14]             512
            ReLU-403          [32, 256, 14, 14]               0
          Conv2d-404          [32, 256, 14, 14]         589,824
     BatchNorm2d-405          [32, 256, 14, 14]             512
            ReLU-406          [32, 256, 14, 14]               0
          Conv2d-407         [32, 1024, 14, 14]         262,144
     BatchNorm2d-408         [32, 1024, 14, 14]           2,048
            ReLU-409         [32, 1024, 14, 14]               0
      BottleNeck-410         [32, 1024, 14, 14]               0
          Conv2d-411          [32, 256, 14, 14]         262,144
     BatchNorm2d-412          [32, 256, 14, 14]             512
            ReLU-413          [32, 256, 14, 14]               0
          Conv2d-414          [32, 256, 14, 14]         589,824
     BatchNorm2d-415          [32, 256, 14, 14]             512
            ReLU-416          [32, 256, 14, 14]               0
          Conv2d-417         [32, 1024, 14, 14]         262,144
     BatchNorm2d-418         [32, 1024, 14, 14]           2,048
            ReLU-419         [32, 1024, 14, 14]               0
      BottleNeck-420         [32, 1024, 14, 14]               0
          Conv2d-421          [32, 256, 14, 14]         262,144
     BatchNorm2d-422          [32, 256, 14, 14]             512
            ReLU-423          [32, 256, 14, 14]               0
          Conv2d-424          [32, 256, 14, 14]         589,824
     BatchNorm2d-425          [32, 256, 14, 14]             512
            ReLU-426          [32, 256, 14, 14]               0
          Conv2d-427         [32, 1024, 14, 14]         262,144
     BatchNorm2d-428         [32, 1024, 14, 14]           2,048
            ReLU-429         [32, 1024, 14, 14]               0
      BottleNeck-430         [32, 1024, 14, 14]               0
          Conv2d-431          [32, 256, 14, 14]         262,144
     BatchNorm2d-432          [32, 256, 14, 14]             512
            ReLU-433          [32, 256, 14, 14]               0
          Conv2d-434          [32, 256, 14, 14]         589,824
     BatchNorm2d-435          [32, 256, 14, 14]             512
            ReLU-436          [32, 256, 14, 14]               0
          Conv2d-437         [32, 1024, 14, 14]         262,144
     BatchNorm2d-438         [32, 1024, 14, 14]           2,048
            ReLU-439         [32, 1024, 14, 14]               0
      BottleNeck-440         [32, 1024, 14, 14]               0
          Conv2d-441          [32, 256, 14, 14]         262,144
     BatchNorm2d-442          [32, 256, 14, 14]             512
            ReLU-443          [32, 256, 14, 14]               0
          Conv2d-444          [32, 256, 14, 14]         589,824
     BatchNorm2d-445          [32, 256, 14, 14]             512
            ReLU-446          [32, 256, 14, 14]               0
          Conv2d-447         [32, 1024, 14, 14]         262,144
     BatchNorm2d-448         [32, 1024, 14, 14]           2,048
            ReLU-449         [32, 1024, 14, 14]               0
      BottleNeck-450         [32, 1024, 14, 14]               0
          Conv2d-451          [32, 256, 14, 14]         262,144
     BatchNorm2d-452          [32, 256, 14, 14]             512
            ReLU-453          [32, 256, 14, 14]               0
          Conv2d-454          [32, 256, 14, 14]         589,824
     BatchNorm2d-455          [32, 256, 14, 14]             512
            ReLU-456          [32, 256, 14, 14]               0
          Conv2d-457         [32, 1024, 14, 14]         262,144
     BatchNorm2d-458         [32, 1024, 14, 14]           2,048
            ReLU-459         [32, 1024, 14, 14]               0
      BottleNeck-460         [32, 1024, 14, 14]               0
          Conv2d-461          [32, 256, 14, 14]         262,144
     BatchNorm2d-462          [32, 256, 14, 14]             512
            ReLU-463          [32, 256, 14, 14]               0
          Conv2d-464          [32, 256, 14, 14]         589,824
     BatchNorm2d-465          [32, 256, 14, 14]             512
            ReLU-466          [32, 256, 14, 14]               0
          Conv2d-467         [32, 1024, 14, 14]         262,144
     BatchNorm2d-468         [32, 1024, 14, 14]           2,048
            ReLU-469         [32, 1024, 14, 14]               0
      BottleNeck-470         [32, 1024, 14, 14]               0
          Conv2d-471          [32, 256, 14, 14]         262,144
     BatchNorm2d-472          [32, 256, 14, 14]             512
            ReLU-473          [32, 256, 14, 14]               0
          Conv2d-474          [32, 256, 14, 14]         589,824
     BatchNorm2d-475          [32, 256, 14, 14]             512
            ReLU-476          [32, 256, 14, 14]               0
          Conv2d-477         [32, 1024, 14, 14]         262,144
     BatchNorm2d-478         [32, 1024, 14, 14]           2,048
            ReLU-479         [32, 1024, 14, 14]               0
      BottleNeck-480         [32, 1024, 14, 14]               0
          Conv2d-481          [32, 512, 14, 14]         524,288
     BatchNorm2d-482          [32, 512, 14, 14]           1,024
            ReLU-483          [32, 512, 14, 14]               0
          Conv2d-484            [32, 512, 7, 7]       2,359,296
     BatchNorm2d-485            [32, 512, 7, 7]           1,024
            ReLU-486            [32, 512, 7, 7]               0
          Conv2d-487           [32, 2048, 7, 7]       1,048,576
     BatchNorm2d-488           [32, 2048, 7, 7]           4,096
          Conv2d-489           [32, 2048, 7, 7]       2,097,152
     BatchNorm2d-490           [32, 2048, 7, 7]           4,096
            ReLU-491           [32, 2048, 7, 7]               0
      BottleNeck-492           [32, 2048, 7, 7]               0
          Conv2d-493            [32, 512, 7, 7]       1,048,576
     BatchNorm2d-494            [32, 512, 7, 7]           1,024
            ReLU-495            [32, 512, 7, 7]               0
          Conv2d-496            [32, 512, 7, 7]       2,359,296
     BatchNorm2d-497            [32, 512, 7, 7]           1,024
            ReLU-498            [32, 512, 7, 7]               0
          Conv2d-499           [32, 2048, 7, 7]       1,048,576
     BatchNorm2d-500           [32, 2048, 7, 7]           4,096
            ReLU-501           [32, 2048, 7, 7]               0
      BottleNeck-502           [32, 2048, 7, 7]               0
          Conv2d-503            [32, 512, 7, 7]       1,048,576
     BatchNorm2d-504            [32, 512, 7, 7]           1,024
            ReLU-505            [32, 512, 7, 7]               0
          Conv2d-506            [32, 512, 7, 7]       2,359,296
     BatchNorm2d-507            [32, 512, 7, 7]           1,024
            ReLU-508            [32, 512, 7, 7]               0
          Conv2d-509           [32, 2048, 7, 7]       1,048,576
     BatchNorm2d-510           [32, 2048, 7, 7]           4,096
            ReLU-511           [32, 2048, 7, 7]               0
      BottleNeck-512           [32, 2048, 7, 7]               0
AdaptiveAvgPool2d-513           [32, 2048, 1, 1]               0
          Linear-514                   [32, 10]          20,490
================================================================
Total params: 58,164,298
Trainable params: 58,164,298
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 18.38
Forward/backward pass size (MB): 19410.63
Params size (MB): 221.88
Estimated Total Size (MB): 19650.88
----------------------------------------------------------------
Epoch 1/100, current lr = 0.001
train loss: 0.066098, val loss: 0.061702, accuracy: 28.78%, epoch time: 1.85 min
Epoch 2/100, current lr = 0.001
train loss: 0.054644, val loss: 0.072890, accuracy: 30.35%, epoch time: 1.85 min
Epoch 3/100, current lr = 0.001
train loss: 0.054702, val loss: 0.063857, accuracy: 25.44%, epoch time: 1.85 min
Epoch 4/100, current lr = 0.001
train loss: 0.055947, val loss: 0.054286, accuracy: 31.56%, epoch time: 1.84 min
Epoch 5/100, current lr = 0.001
train loss: 0.052554, val loss: 0.053111, accuracy: 31.34%, epoch time: 1.85 min
Epoch 6/100, current lr = 0.001
train loss: 0.051408, val loss: 0.057672, accuracy: 33.07%, epoch time: 1.85 min
Epoch 7/100, current lr = 0.001
train loss: 0.050622, val loss: 0.053763, accuracy: 32.80%, epoch time: 1.85 min
Epoch 8/100, current lr = 0.001
train loss: 0.049307, val loss: 0.049014, accuracy: 38.86%, epoch time: 1.84 min
Epoch 9/100, current lr = 0.001
train loss: 0.047650, val loss: 0.046404, accuracy: 40.61%, epoch time: 1.85 min
Epoch 10/100, current lr = 0.001
train loss: 0.046714, val loss: 0.058705, accuracy: 36.36%, epoch time: 1.84 min
Epoch 11/100, current lr = 0.001
train loss: 0.045259, val loss: 0.050459, accuracy: 40.24%, epoch time: 1.85 min
Epoch 12/100, current lr = 0.001
train loss: 0.044647, val loss: 0.082116, accuracy: 35.51%, epoch time: 1.84 min
Epoch 13/100, current lr = 0.001
train loss: 0.045406, val loss: 0.084891, accuracy: 35.12%, epoch time: 1.84 min
Epoch 14/100, current lr = 0.001
train loss: 0.042116, val loss: 0.057365, accuracy: 44.26%, epoch time: 1.84 min
Epoch 15/100, current lr = 0.001
train loss: 0.039306, val loss: 0.041255, accuracy: 50.84%, epoch time: 1.84 min
Epoch 16/100, current lr = 0.001
train loss: 0.038411, val loss: 0.039601, accuracy: 53.96%, epoch time: 1.84 min
Epoch 17/100, current lr = 0.001
train loss: 0.036640, val loss: 0.044707, accuracy: 48.06%, epoch time: 1.85 min
Epoch 18/100, current lr = 0.001
train loss: 0.034966, val loss: 0.040788, accuracy: 52.90%, epoch time: 1.85 min
Epoch 19/100, current lr = 0.001
train loss: 0.034401, val loss: 0.090137, accuracy: 41.80%, epoch time: 1.84 min
Epoch 20/100, current lr = 0.001
train loss: 0.032786, val loss: 0.033375, accuracy: 60.88%, epoch time: 1.84 min
Epoch 21/100, current lr = 0.001
train loss: 0.031700, val loss: 0.042988, accuracy: 52.01%, epoch time: 1.85 min
Epoch 22/100, current lr = 0.001
train loss: 0.031211, val loss: 0.038779, accuracy: 55.50%, epoch time: 1.85 min
Epoch 23/100, current lr = 0.001
train loss: 0.030098, val loss: 0.034298, accuracy: 59.77%, epoch time: 1.84 min
Epoch 24/100, current lr = 0.001
train loss: 0.029118, val loss: 0.035166, accuracy: 59.96%, epoch time: 1.84 min
Epoch 25/100, current lr = 0.001
train loss: 0.028563, val loss: 0.048401, accuracy: 48.01%, epoch time: 1.85 min
Epoch 26/100, current lr = 0.001
train loss: 0.027493, val loss: 0.034543, accuracy: 60.96%, epoch time: 1.85 min
Epoch 27/100, current lr = 0.001
train loss: 0.025892, val loss: 0.035543, accuracy: 61.81%, epoch time: 1.85 min
Epoch 28/100, current lr = 0.001
train loss: 0.025949, val loss: 0.032814, accuracy: 62.00%, epoch time: 1.85 min
Epoch 29/100, current lr = 0.001
train loss: 0.024658, val loss: 0.048951, accuracy: 54.97%, epoch time: 1.84 min
Epoch 30/100, current lr = 0.001
train loss: 0.024290, val loss: 0.033523, accuracy: 62.90%, epoch time: 1.85 min
Epoch 31/100, current lr = 0.001
train loss: 0.024119, val loss: 0.071447, accuracy: 57.26%, epoch time: 1.85 min
Epoch 32/100, current lr = 0.001
train loss: 0.021797, val loss: 0.030873, accuracy: 65.29%, epoch time: 1.85 min
Epoch 33/100, current lr = 0.001
train loss: 0.022601, val loss: 0.047400, accuracy: 53.15%, epoch time: 1.84 min
Epoch 34/100, current lr = 0.001
train loss: 0.020005, val loss: 0.037572, accuracy: 60.30%, epoch time: 1.84 min
Epoch 35/100, current lr = 0.001
train loss: 0.018980, val loss: 0.037666, accuracy: 63.31%, epoch time: 1.85 min
Epoch 36/100, current lr = 0.001
train loss: 0.018819, val loss: 0.038514, accuracy: 61.79%, epoch time: 1.85 min
Epoch 37/100, current lr = 0.001
train loss: 0.017492, val loss: 0.036891, accuracy: 63.79%, epoch time: 1.85 min
Epoch 38/100, current lr = 0.001
train loss: 0.016823, val loss: 0.032572, accuracy: 67.04%, epoch time: 1.85 min
Epoch 39/100, current lr = 0.001
train loss: 0.016560, val loss: 0.041550, accuracy: 59.30%, epoch time: 1.84 min
Epoch 40/100, current lr = 0.001
train loss: 0.015242, val loss: 0.032185, accuracy: 66.85%, epoch time: 1.85 min
Epoch 41/100, current lr = 0.001
train loss: 0.014665, val loss: 0.033766, accuracy: 65.97%, epoch time: 1.84 min
Epoch 42/100, current lr = 0.001
train loss: 0.013460, val loss: 0.040329, accuracy: 63.81%, epoch time: 1.84 min
Epoch 43/100, current lr = 0.001
train loss: 0.011694, val loss: 0.040240, accuracy: 64.35%, epoch time: 1.84 min
Epoch 44/100, current lr = 0.0001
train loss: 0.006321, val loss: 0.032543, accuracy: 70.73%, epoch time: 1.85 min
Epoch 45/100, current lr = 0.0001
train loss: 0.003818, val loss: 0.035935, accuracy: 71.31%, epoch time: 1.85 min
Epoch 46/100, current lr = 0.0001
train loss: 0.003045, val loss: 0.037899, accuracy: 70.89%, epoch time: 1.84 min
Epoch 47/100, current lr = 0.0001
train loss: 0.002490, val loss: 0.039848, accuracy: 70.90%, epoch time: 1.85 min
Epoch 48/100, current lr = 0.0001
train loss: 0.002101, val loss: 0.040574, accuracy: 71.39%, epoch time: 1.84 min
Epoch 49/100, current lr = 0.0001
train loss: 0.001778, val loss: 0.044990, accuracy: 71.00%, epoch time: 1.85 min
Epoch 50/100, current lr = 0.0001
train loss: 0.001372, val loss: 0.045701, accuracy: 71.17%, epoch time: 1.84 min
Epoch 51/100, current lr = 0.0001
train loss: 0.001429, val loss: 0.046864, accuracy: 70.85%, epoch time: 1.85 min
Epoch 52/100, current lr = 0.0001
train loss: 0.001192, val loss: 0.047805, accuracy: 70.88%, epoch time: 1.84 min
Epoch 53/100, current lr = 0.0001
train loss: 0.001320, val loss: 0.049102, accuracy: 70.78%, epoch time: 1.84 min
Epoch 54/100, current lr = 0.0001
train loss: 0.001108, val loss: 0.050189, accuracy: 70.67%, epoch time: 1.85 min
Epoch 55/100, current lr = 1e-05
train loss: 0.000759, val loss: 0.049009, accuracy: 70.86%, epoch time: 1.84 min
Epoch 56/100, current lr = 1e-05
train loss: 0.000831, val loss: 0.049723, accuracy: 70.53%, epoch time: 1.85 min
Epoch 57/100, current lr = 1e-05
train loss: 0.000725, val loss: 0.049238, accuracy: 71.03%, epoch time: 1.85 min
Epoch 58/100, current lr = 1e-05
train loss: 0.000477, val loss: 0.049849, accuracy: 70.84%, epoch time: 1.85 min
Epoch 59/100, current lr = 1e-05
train loss: 0.000600, val loss: 0.050255, accuracy: 70.54%, epoch time: 1.85 min
Epoch 60/100, current lr = 1e-05
train loss: 0.000533, val loss: 0.050379, accuracy: 70.75%, epoch time: 1.85 min
Epoch 61/100, current lr = 1e-05
train loss: 0.000497, val loss: 0.050582, accuracy: 70.91%, epoch time: 1.85 min
Epoch 62/100, current lr = 1e-05
train loss: 0.000595, val loss: 0.050499, accuracy: 71.19%, epoch time: 1.85 min
Epoch 63/100, current lr = 1e-05
train loss: 0.000436, val loss: 0.050601, accuracy: 70.61%, epoch time: 1.85 min
Epoch 64/100, current lr = 1e-05
train loss: 0.000461, val loss: 0.051499, accuracy: 70.83%, epoch time: 1.84 min
Epoch 65/100, current lr = 1e-05
train loss: 0.000401, val loss: 0.051153, accuracy: 70.75%, epoch time: 1.85 min
Epoch 66/100, current lr = 1.0000000000000002e-06
train loss: 0.000643, val loss: 0.052748, accuracy: 70.83%, epoch time: 1.85 min
Epoch 67/100, current lr = 1.0000000000000002e-06
train loss: 0.000354, val loss: 0.051742, accuracy: 70.84%, epoch time: 1.85 min
Epoch 68/100, current lr = 1.0000000000000002e-06
train loss: 0.000417, val loss: 0.050960, accuracy: 70.99%, epoch time: 1.85 min
Epoch 69/100, current lr = 1.0000000000000002e-06
train loss: 0.000481, val loss: 0.051183, accuracy: 70.93%, epoch time: 1.84 min
Epoch 70/100, current lr = 1.0000000000000002e-06
train loss: 0.000935, val loss: 0.051655, accuracy: 70.88%, epoch time: 1.85 min
Epoch 71/100, current lr = 1.0000000000000002e-06
train loss: 0.000633, val loss: 0.052283, accuracy: 70.66%, epoch time: 1.85 min
Epoch 72/100, current lr = 1.0000000000000002e-06
train loss: 0.000409, val loss: 0.050961, accuracy: 70.84%, epoch time: 1.85 min
Epoch 73/100, current lr = 1.0000000000000002e-06
train loss: 0.000433, val loss: 0.051736, accuracy: 70.96%, epoch time: 1.84 min
Epoch 74/100, current lr = 1.0000000000000002e-06
train loss: 0.000426, val loss: 0.050503, accuracy: 71.05%, epoch time: 1.84 min
Epoch 75/100, current lr = 1.0000000000000002e-06
train loss: 0.000461, val loss: 0.049354, accuracy: 70.74%, epoch time: 1.85 min
Epoch 76/100, current lr = 1.0000000000000002e-06
train loss: 0.000775, val loss: 0.052336, accuracy: 70.66%, epoch time: 1.85 min
Epoch 77/100, current lr = 1.0000000000000002e-07
train loss: 0.000494, val loss: 0.051768, accuracy: 71.01%, epoch time: 1.85 min
Epoch 78/100, current lr = 1.0000000000000002e-07
train loss: 0.000557, val loss: 0.051977, accuracy: 70.96%, epoch time: 1.85 min
Epoch 79/100, current lr = 1.0000000000000002e-07
train loss: 0.000392, val loss: 0.051581, accuracy: 70.88%, epoch time: 1.85 min
Epoch 80/100, current lr = 1.0000000000000002e-07
train loss: 0.000343, val loss: 0.051573, accuracy: 71.03%, epoch time: 1.85 min
Epoch 81/100, current lr = 1.0000000000000002e-07
train loss: 0.000363, val loss: 0.051140, accuracy: 70.94%, epoch time: 1.85 min
Epoch 82/100, current lr = 1.0000000000000002e-07
train loss: 0.000455, val loss: 0.051480, accuracy: 70.85%, epoch time: 1.85 min
Epoch 83/100, current lr = 1.0000000000000002e-07
train loss: 0.000490, val loss: 0.051857, accuracy: 70.97%, epoch time: 1.85 min
Epoch 84/100, current lr = 1.0000000000000002e-07
train loss: 0.000461, val loss: 0.051669, accuracy: 71.06%, epoch time: 1.84 min
Epoch 85/100, current lr = 1.0000000000000002e-07
train loss: 0.000538, val loss: 0.052495, accuracy: 70.80%, epoch time: 1.85 min
Epoch 86/100, current lr = 1.0000000000000002e-07
train loss: 0.000492, val loss: 0.052000, accuracy: 70.93%, epoch time: 1.86 min
Epoch 87/100, current lr = 1.0000000000000002e-07
train loss: 0.000367, val loss: 0.050894, accuracy: 70.85%, epoch time: 1.85 min
Epoch 88/100, current lr = 1.0000000000000004e-08
train loss: 0.000417, val loss: 0.051762, accuracy: 71.00%, epoch time: 1.86 min
Epoch 89/100, current lr = 1.0000000000000004e-08
train loss: 0.000381, val loss: 0.051387, accuracy: 70.80%, epoch time: 1.85 min
Epoch 90/100, current lr = 1.0000000000000004e-08
train loss: 0.000440, val loss: 0.051955, accuracy: 70.85%, epoch time: 1.84 min
Epoch 91/100, current lr = 1.0000000000000004e-08
train loss: 0.000442, val loss: 0.050555, accuracy: 70.96%, epoch time: 1.85 min
Epoch 92/100, current lr = 1.0000000000000004e-08
train loss: 0.000468, val loss: 0.051532, accuracy: 70.89%, epoch time: 1.85 min
Epoch 93/100, current lr = 1.0000000000000004e-08
train loss: 0.000386, val loss: 0.050259, accuracy: 71.15%, epoch time: 1.85 min
Epoch 94/100, current lr = 1.0000000000000004e-08
train loss: 0.000495, val loss: 0.051038, accuracy: 70.85%, epoch time: 1.84 min
Epoch 95/100, current lr = 1.0000000000000004e-08
train loss: 0.000493, val loss: 0.051306, accuracy: 70.70%, epoch time: 1.84 min
Epoch 96/100, current lr = 1.0000000000000004e-08
train loss: 0.000380, val loss: 0.051431, accuracy: 70.96%, epoch time: 1.85 min
Epoch 97/100, current lr = 1.0000000000000004e-08
train loss: 0.000429, val loss: 0.051267, accuracy: 71.03%, epoch time: 1.85 min
Epoch 98/100, current lr = 1.0000000000000004e-08
train loss: 0.000381, val loss: 0.051743, accuracy: 70.78%, epoch time: 1.85 min
Epoch 99/100, current lr = 1.0000000000000004e-08
train loss: 0.000549, val loss: 0.051364, accuracy: 70.88%, epoch time: 1.85 min
Epoch 100/100, current lr = 1.0000000000000004e-08
train loss: 0.000376, val loss: 0.051915, accuracy: 71.08%, epoch time: 1.84 min
Training complete in 184.69 min
